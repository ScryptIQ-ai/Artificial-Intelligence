<!DOCTYPE html>
<html>
<head>
    <!-- Favicons -->
    <link rel="icon" type="image/x-icon" href="../assets/favicon.ico">
    <link rel="icon" type="image/png" sizes="32x32" href="../assets/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../assets/favicon-16x16.png">
    <link rel="apple-touch-icon" sizes="192x192" href="../assets/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="192x192" href="../assets/android-chrome-192x192.png">
    <link rel="icon" type="image/png" sizes="512x512" href="../assets/android-chrome-512x512.png">
    
    <!-- Core Stylesheets -->
    <link rel="stylesheet" href=../assets/colours.css>
    <link rel="stylesheet" href="../assets/shared-styles.css">
    <link rel="stylesheet" href="../assets/module_card.css">
    
    <!-- Meta Tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>L2D - AI2 - Glossary</title>
    
    <style>
        /* Override sidebar styling since we're not using it */
        body {
            background-color: var(--background) !important;
            color: var(--text-primary);
            margin: 0 !important;
            padding: 0 !important;
            min-height: 100vh;
            display: flex !important;
            justify-content: center !important;
            align-items: flex-start !important;
            flex-direction: column !important;
        }

        .main-content {
            width: 100% !important;
            max-width: 1200px !important;
            padding: 0 20px !important;
            box-sizing: border-box !important;
            margin: 0 auto !important;
            position: relative !important;
            left: auto !important;
            right: auto !important;
            transform: none !important;
        }

        /* Additional centering overrides */
        #main-content {
            margin-left: auto !important;
            margin-right: auto !important;
            text-align: left !important;
        }

        .logo-container {
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px 0;
        }

        .logo-container img {
            width: clamp(60px, 10vw, 120px);
            height: clamp(60px, 10vw, 120px);
            margin-right: 10px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .glossary-entry {
            margin-bottom: 25px;
            padding-bottom: 20px;
            border-bottom: 1px solid rgba(0, 0, 0, 0.1);
        }

        .glossary-entry:last-child {
            border-bottom: none;
        }

        .glossary-term {
            font-size: 18px;
            font-weight: 600;
            color: var(--remember);
            margin-bottom: 8px;
        }

        .glossary-definition {
            line-height: 1.6;
            color: var(--text-secondary);
        }

        @media (max-width: 768px) {
            .logo-container img {
                height: 60px;
            }
            
            .glossary-term {
                font-size: 16px;
            }
        }
    </style>
</head>
<body>
    <div id="main-content" class="main-content">
        <div class="top-navbar">
            <div class="logo-container">
                <h1 class="page-title">Artificial Intelligence 2 - Glossary</h1>
            </div>
        </div>

        <div class="module-card">
            <div class="module-header">
                Glossary <span class="module-tag">AI2</span>
            </div>
            <div class="module-body">
                
                <div class="glossary-entry">
                    <strong>Activation Function</strong>: A function (like ReLU) applied element-wise to introduce non-linearity, enabling the network to learn complex patterns.
                </div>
                <div class="glossary-entry">
                    <strong>AUC (Area Under the Curve)</strong>: A single scalar value derived from the ROC curve, representing the model&#x27;s ability to distinguish between classes (higher is better).
                </div>
                <div class="glossary-entry">
                    <strong>Average Pooling</strong>: A pooling operation that takes the average value from a region of the feature map.
                </div>
                <div class="glossary-entry">
                    <strong>Backpropagation (Backward Pass)</strong>: The process of calculating gradients of the loss function with respect to each weight in the network, used to update those weights.
                </div>
                <div class="glossary-entry">
                    <strong>Batch Normalisation</strong>: A technique that stabilises training by normalising the activations within each mini-batch.
                </div>
                <div class="glossary-entry">
                    <strong>Cellpose</strong>: A generalist algorithm for cellular segmentation that works across different cell types and imaging modalities.
                </div>
                <div class="glossary-entry">
                    <strong>Confusion Matrix</strong>: A table used to evaluate the performance of a classification model by comparing actual vs predicted labels.
                </div>
                <div class="glossary-entry">
                    <strong>Convolutional Layers</strong>: Layers that apply filters (kernels) to the input image to extract features such as edges, textures, and shapes.
                </div>
                <div class="glossary-entry">
                    <strong>Convolutional Neural Network (CNN)</strong>: A model architecture often used for image recognition tasks.
                </div>
                <div class="glossary-entry">
                    <strong>Cross Entropy Loss</strong>: A loss function used for classification tasks that measures the difference between predicted probabilities and actual labels.
                </div>
                <div class="glossary-entry">
                    <strong>Dropout</strong>: A regularisation technique where randomly selected neurons are ignored during training, helping to prevent overfitting.
                </div>
                <div class="glossary-entry">
                    <strong>Early Stopping</strong>: A form of regularisation used to avoid overfitting by stopping the training process when the model&#x27;s performance on a validation set starts to degrade.
                </div>
                <div class="glossary-entry">
                    <strong>F1 Score</strong>: The harmonic mean of precision and recall, providing a single metric that balances both.
                </div>
                <div class="glossary-entry">
                    <strong>Feature Map</strong>: The output of a convolution operation, highlighting specific patterns in the input image.
                </div>
                <div class="glossary-entry">
                    <strong>FPR (False Positive Rate)</strong>: Measures the proportion of actual negatives incorrectly identified as positives.
                </div>
                <div class="glossary-entry">
                    <strong>Fully Connected Layers (Dense Layers)</strong>: Layers where every neuron is connected to every neuron in the previous layer, typically used for classification based on learned features.
                </div>
                <div class="glossary-entry">
                    <strong>Gradient Descent</strong>: An optimisation algorithm used to minimise the loss function by iteratively adjusting model parameters.
                </div>
                <div class="glossary-entry">
                    <strong>ImageNet</strong>: A large database of images used for training visual organisers.
                </div>
                <div class="glossary-entry">
                    <strong>Input Layer</strong>: Receives the raw input data, usually images represented as matrices of pixel values.
                </div>
                <div class="glossary-entry">
                    <strong>Kernel / Filter</strong>: A small matrix (sliding window) applied to an image to compute feature maps through dot products.
                </div>
                <div class="glossary-entry">
                    <strong>Macro F1 Score</strong>: The average F1 score calculated across all classes, giving equal weight to each class.
                </div>
                <div class="glossary-entry">
                    <strong>Max Pooling</strong>: A pooling operation that takes the maximum value from a region of the feature map.
                </div>
                <div class="glossary-entry">
                    <strong>Overfitting</strong>: When a model learns specific patterns in the training data too well, failing to generalise to new, unseen data.
                </div>
                <div class="glossary-entry">
                    <strong>Padding</strong>: Extra pixels added to the edges of an image to ensure the kernel covers the entire image and control the output size.
                </div>
                <div class="glossary-entry">
                    <strong>Pooling Layers</strong>: Layers that downsample feature maps to reduce spatial dimensions while retaining important features.
                </div>
                <div class="glossary-entry">
                    <strong>Precision</strong>: The proportion of predicted positives that were actually positive.
                </div>
                <div class="glossary-entry">
                    <strong>PyTorch</strong>: An open-source machine learning framework for Python that provides tools for building, training and deploying neural networks.
                </div>
                <div class="glossary-entry">
                    <strong>Recall</strong>: The proportion of actual positives that were correctly predicted as positive.
                </div>
                <div class="glossary-entry">
                    <strong>ReduceLROnPlateau</strong>: A learning rate scheduler that reduces the learning rate when the validation loss stops improving.
                </div>
                <div class="glossary-entry">
                    <strong>ReLU (Rectified Linear Unit)</strong>: A common activation function that outputs the input directly if it is positive, otherwise, it outputs zero.
                </div>
                <div class="glossary-entry">
                    <strong>ROC Curve (Receiver Operating Characteristic)</strong>: A plot showing the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.
                </div>
                <div class="glossary-entry">
                    <strong>Softmax</strong>: An activation function that converts a vector of numbers into a vector of probabilities that sum to one.
                </div>
                <div class="glossary-entry">
                    <strong>Stride</strong>: The number of pixels by which the filter (kernel) shifts over the input image during convolution.
                </div>
                <div class="glossary-entry">
                    <strong>Supervised Learning</strong>: A type of machine learning where the model is trained on a labelled dataset, learning to map inputs to correct outputs.
                </div>
                <div class="glossary-entry">
                    <strong>TPR (True Positive Rate)</strong>: Also known as recall or sensitivity, measures the proportion of actual positives correctly identified.
                </div>
                <div class="glossary-entry">
                    <strong>Transfer Learning</strong>: A machine learning technique where a model developed for one task is reused as the starting point for a model on a second task.
                </div>
                <div class="glossary-entry">
                    <strong>Visual Transformers</strong>: A machine learning model for image classification that utilises the transformer architecture.
                </div>
            </div>
        </div>

        <div class="footer">
            <div>© Built with parchmentIQ copyright of scryptIQ</div>
            <div>© L2D is copyright UCL 2025</div>
        </div>
    </div>
</body>
</html>
        