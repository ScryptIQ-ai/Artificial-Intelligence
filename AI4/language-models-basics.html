<!DOCTYPE html>
<html>
<head>
    <!-- MathJax for mathematical notation -->
    <script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$']],
            displayMath: [['$$', '$$']],
            processEscapes: true
        },
        svg: {
            fontCache: 'global'
        }
    };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
    
    <!-- Syntax Highlighting with highlight.js -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>
    
    <!-- Favicons -->
    <link rel="icon" type="image/x-icon" href="../assets/favicon.ico">
    <link rel="icon" type="image/png" sizes="32x32" href="../assets/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../assets/favicon-16x16.png">
    <link rel="apple-touch-icon" sizes="192x192" href="../assets/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="192x192" href="../assets/android-chrome-192x192.png">
    <link rel="icon" type="image/png" sizes="512x512" href="../assets/android-chrome-512x512.png">
    
    <!-- Core Stylesheets -->
    <link rel="stylesheet" href=../assets/colours.css>
    <link rel="stylesheet" href="../assets/shared-styles.css">
    <link rel="stylesheet" href="../assets/nav-bar.css">
    <link rel="stylesheet" href="../assets/module_card.css">
    <link rel="stylesheet" href="../assets/learning_outcomes.css">
    <link rel="stylesheet" href="../assets/learning_lists.css">
    <link rel="stylesheet" href="../assets/box_styles.css">
    <link rel="stylesheet" href="../assets/code_styles.css">
    <link rel="stylesheet" href="../assets/static_output.css">

    <!-- Meta Tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>L2D - AI4 - Protein Language Models Fundamentals</title>
        
</head>
<body>
    
    <!-- Sidebar Navigation -->
    <div id="sidebar" class="sidebar">
        <div class="sidebar-header">
            <a href="../homepage.html" style="text-decoration: none; display: inline-block;">
                <img src="../assets/scryptIQ_logo_dark.png" alt="scryptIQ Logo" class="sidebar-logo">
            </a>
        </div>

        <h3>Content</h3>
        <ul>
            <li><a href="./introduction.html" class="">Introduction</a></li><li><a href="./data-processing.html">Processing the data</a></li>
            <li>
                <div class="nav-toggle active" data-target="expandable-section-2">
                    Protein Language Models Fundamentals
                    <span class="toggle-icon">‚ñº</span>
                </div>
                <ul class="nested-nav expanded" id="expandable-section-2"><li><a href="#introduction">Introduction</a></li><li><a href="#encoding">Encoding</a></li><li><a href="#embedding">Embedding</a></li><li><a href="#loading-the-model">Loading the Model</a></li><li><a href="#tokenisation">Tokenisation</a></li><li><a href="#fetch-an-embedding">Fetch an embedding</a></li><li><a href="#embedding-extraction">Embedding Extraction</a></li><li><a href="#embeddings-to-disk">Embeddings to disk</a></li><li><a href="#summary">Summary</a></li>
                </ul>
            </li><li><a href="./classifying-embeddings.html">Classifying Embeddings</a></li><li><a href="./evaluating.html">Evaluating the Model</a></li><li><a href="./assignment.html">Assignment</a></li><li><a href="./feedback.html">Feedback</a></li>
        </ul>

        <h3 class="collapsible-header collapsed">
            Resources
            <span class="collapse-icon">‚ñ∫</span>
        </h3>
        <div class="collapsible-content collapsed">
            <ul>
                <li><a href="./glossary.html">Glossary</a></li><li><a href="./downloads.html">Downloads</a></li><li><a href="../HB/introduction.html">Handbook</a></li>
            </ul>
        </div>

        <h3 class="collapsible-header collapsed">
            Previous Modules
            <span class="collapse-icon">‚ñ∫</span>
        </h3>
        <div class="collapsible-content collapsed">
            <ul>
            <li><a href="../AI1/introduction.html">AI1</a></li>
            <li><a href="../AI2/introduction.html">AI2</a></li>
            <li><a href="../AI3/introduction.html">AI3</a></li>
        </ul>
        </div>

        <h3>
            <li><a href="./report-issue.html">Report an Issue</a></li>
        </h3>
    </div>
    
    <!-- Sidebar Toggle Button -->
    <button id="sidebar-toggle" class="sidebar-toggle">‚ùÆ</button>
    
    <!-- Main Content Area -->
    <div id="main-content" class="main-content">
        <!-- Top Navigation Bar -->
        <div class="top-navbar">
            <h1 class="page-title">Artificial Intelligence 4</h1>
            <div class="nav-actions">
                <a href="../homepage.html" class="text-button" title="Materials homepage">
                    Homepage
                </a>
                <a href="https://learntodiscover.ai/my-cohorts/" class="text-button" title="Find out more about us">
                    Learn to Discover
                </a>
            </div>
        </div>

        
            <div class="module-card" id="introduction">
                <div class="module-header">
                    Protein Language Models Fundamentals <span class="module-tag">AI4</span>
                </div>
                <div class="module-body">
                    <h3>Learning Objectives</h3>
                    <div class="learning-outcomes">
                        <div class="outcome-item">
                    <span class="outcome-number">1</span>
                    <span class="outcome-text">What is encoding?</span>
                </div>
<div class="outcome-item">
                    <span class="outcome-number">2</span>
                    <span class="outcome-text">What is a embedding?</span>
                </div>
<div class="outcome-item">
                    <span class="outcome-number">3</span>
                    <span class="outcome-text">Downloading a model from HuggingFace</span>
                </div>
<div class="outcome-item">
                    <span class="outcome-number">4</span>
                    <span class="outcome-text">How to get feature embeddings for your sequence</span>
                </div>
                    </div>
                    <h3>Introduction</h3>
                    <p>In this section we will run through the fundamental steps and components in a <strong>Protein Language Model</strong>, starting with encoding our protein sequence into a form a computer can recognise to converting it to a <em>vector</em> that contains its information about the sequence and its individual amino acids.</p>
                </div>
            </div>
            
            <div class="module-card" id="encoding">
                <div class="module-body">
                    <div class="module-section">
                        <h3>Encoding</h3>
                        <p>Previously we generated several mutated seqeunces given our data. These are represented as a string of single, captital letters. This method of encoding is good for humans, but for computers the sequence needs to be converted into numbers.<br><br>As typical with machine learning this numerical representation will be <em>tensor</em> of values where each <strong>vector</strong> will denote which amino acid is in each position.</p>
        <div class="info-box key-terms-box">
            <div class="box-title">
                <span class="box-icon"></span>
                KEY TERMS
            </div>
            <div class="box-content">
                <p><strong>Vector</strong>: A sequence of numbers that represents a point in a multi-dimensional space.</p>
            </div>
        </div>
        <p>Each protein sequence is composed of <strong>20 common types</strong> of amino acids. Therefore, one of the simplest methods to encode a protein sequence is through <strong>one-hot encoding</strong>. In this encoding scheme, each amino acid is represented by a binary vector of length 20. Each position in the vector corresponds to one of the 20 amino acids, and the position representing the specific amino acid in the sequence is set to 1, while all other positions are set to 0. This method effectively transforms the categorical amino acid data into a numerical format that can be used in machine learning models.<br><br>For example, we have a protein sequence: ACDET, and we would like to identify &#x27;A&#x27; as 0, &#x27;C&#x27; as 1, &#x27;D&#x27; as 2, and so forth up to &#x27;T&#x27; as 19 as the following pattern:</p><p>A one-hot encoding for a protein sequence containing the amino acids A, C, D, E, and T might be represented as follows:</p><table class="markdown-table">
<thead>
<tr>
<th>Amino Acid</th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
<th>11</th>
<th>12</th>
<th>13</th>
<th>14</th>
<th>15</th>
<th>16</th>
<th>17</th>
<th>18</th>
<th>19</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>C</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>D</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>E</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>T</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
                    </div>
                </div>
            </div>
            
            <div class="module-card" id="embedding">
                <div class="module-body">
                    <div class="module-section">
                        <h3>Embedding</h3>
                        <p>One-hot encoding is a straightforward way to show what kind of amino acids are in a protein, but it&#x27;s a bit like just knowing someone&#x27;s name without knowing anything more about them. Proteins are more complex than that. To really understand what a protein can do, we need to know more than just the amino acid types; we need to understand how these amino acids interact, how they&#x27;ve evolved, and what physical and chemical properties they have. But gathering all this detailed information for every amino acid in every protein can be overwhelming and often not feasible.<br><br>To make things simpler and more informative, we use <strong>embeddings</strong>. Imagine if you could create a small summary or a &#x27;mini-profile&#x27; for each amino acid that includes not just its name but also hints at its deeper characteristics‚Äîlike its behavior, its role in the protein, and its history. That&#x27;s what an embedding does. It turns each amino acid into a compact set of numbers (this set is what we call a <em>vector</em>). You can decide how many numbers there should be, but each set uniquely reflects crucial aspects of the amino acid. For example, if you have 100 sequences, and assume each protein is so complex that each of the amino acid should be represented by 256 features, your can identify your sequences as a tensor with the shape of <code>[100, 256]</code>.</p>
        <div class="info-box tip-box">
            <div class="box-title">
                <span class="box-icon"></span>
                TIP
            </div>
            <div class="box-content">
                <p>You can find more information about embedding via this link: <a href="https://huggingface.co/spaces/hesamation/primer-llm-embedding?section=what_are_embeddings?">LLM Embeddings</a>.</p>
            </div>
        </div>
        <h4>How to get embedding vectors</h4><p>Protein language models like ESM work in two stages to create meaningful representations of amino acids:<br><br><strong>Stage 1: Initial Embeddings</strong><br>During training on 250 million protein sequences, the model learns a unique numerical representation (embedding vector) for each of the 20 amino acids. These embeddings are stored in the model&#x27;s <strong>embedding layer</strong>. This is the &#x27;mini-profile&#x27; that we mentioned earlier, a numerical capture of the general and historical properties of an amino acid type.<br><br><strong>Stage 2: Contextualisation through Attention</strong><br>However, the same amino acid can play very different roles depending on its context in the sequence. This is where the <strong>attention mechanism</strong> comes in. After the initial embeddings are assigned, the model passes them through multiple attention layers (33 layers in ESM-1b). Each layer refines the embeddings by considering the surrounding amino acids. The result is that an alanine at position 50 will have a different final embedding depending on whether it&#x27;s surrounded by hydrophobic residues in a protein core or charged residues on the surface.<br><br>The resulting contextualised embeddings from protein language models have been proven to implicitly capture structural and evolutionary characteristics of proteins. This means that even without explicitly programming features like secondary structure or conservation scores into the model, the trained embeddings naturally incorporate this crucial biological information through learning from millions of sequences.<br><br>By utilising the embeddings generated from these pretrained protein language models, we can apply them to various downstream prediction tasks without needing to retrain on massive datasets ourselves.<br><br>For instance, <a href="https://github.com/wlin16/VariPred">VariPred</a> employs embeddings from the <strong>ESM model</strong> to train a missense mutation pathogenicity predictor. A workflow we will be replicating from here on.<br><br><strong>Language models</strong> are not just about predicting the next work or amino acid in a sequence, they are also a rich, pre-encoded insights embedded within a high-dimensional <em>vector</em>.<br><br>With that in mind, let&#x27;s extract <strong>contextualised embeddings</strong> from our prepared protein sequences using one of the most powerful protein language models, <strong>ESM-1b</strong>.</p>
                    </div>
                </div>
            </div>
            
            <div class="module-card" id="loading-the-model">
                <div class="module-body">
                    <div class="module-section">
                        <h3>Loading the Model</h3>
                        <p>Most protein language models with transformer architecture are stored on <a href="https://huggingface.co/">HuggingFace</a>.<br><br>We mentioned it previously at the end of <a href="../AI2/pre-trained-software.html#downloading-pre-trained-modles"><strong>AI2</strong></a>, however here is another brief synopsis:</p>
        <div class="info-box key-terms-box">
            <div class="box-title">
                <span class="box-icon"></span>
                KEY TERMS
            </div>
            <div class="box-content">
                <p>HuggingFace is a platform that centralises various pre-trained models, including protein language models with transformer architecture. It simplifies the process of downloading and training these models, making it easier for researchers and developers to access state-of-the-art models for natural language processing tasks. This platform is important because it promotes reproducibility, standardisation, and collaboration in the field of machine learning. By providing a centralised hub for models, HuggingFace streamlines the workflow of experimenting with different models and accelerates the development of new applications.</p>
            </div>
        </div>
        <h4>Setup</h4><p>To use transformer based models from <strong>huggingface</strong> you will need to install the <a href="https://pypi.org/project/transformers/"><strong>transformers</strong> library</a>, which provides API access to the models. To find the models you want, head to the huggingface website and search for for your use case. Clicking on a model will take you to a page where you can find the model card, which will contain information about the model, including the model&#x27;s name, description, and the code need to load it. For example, see <a href="https://huggingface.co/facebook/esm1b_t33_650M_UR50S">here</a> for the <strong>ESM1b model</strong>.</p>
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-24">import torch
from transformers import EsmModel, AutoTokenizer</code></pre>
            </div>
            
        </div>
        
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-25">SEED = 42
torch.manual_seed(SEED)
# Set the seed for all devices (both CPU and CUDA)
torch.cuda.manual_seed_all(SEED)

# Check if GPU is available
if torch.cuda.is_available():
    # if there are multiple GPUs, choose the first one
    device = torch.device(f&quot;cuda:0&quot;)
    print(f&#x27;There are {torch.cuda.device_count()} GPU(s) available.&#x27;)
    print(f&#x27;Device name: {torch.cuda.get_device_name(0)}&#x27;)
else:
    print(&quot;No GPU detected! Falling back to CPU&quot;)
    # If the GPU is not available, use the CPU
    device = torch.device(&quot;cpu&quot;)</code></pre>
            </div>
            <div class="output-container"><pre class="output-stream">No GPU detected! Falling back to CPU
</pre></div>
        </div>
        
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-26"># Load the ESM model with its pretrained weights
model = EsmModel.from_pretrained(&quot;facebook/esm1b_t33_650M_UR50S&quot;, use_safetensors=True)
model.to(device)

# Load the tokenizer corresponding to the ESM model
tokenizer = AutoTokenizer.from_pretrained(&quot;facebook/esm1b_t33_650M_UR50S&quot;)</code></pre>
            </div>
            <div class="output-container"><pre class="output-result">config.json:   0%|          | 0.00/782 [00:00&lt;?, ?B/s]</pre><pre class="output-result">model.safetensors:   0%|          | 0.00/2.61G [00:00&lt;?, ?B/s]</pre><pre class="output-result">Loading weights:   0%|          | 0/536 [00:00&lt;?, ?it/s]</pre><pre class="output-stderr">[1mEsmModel LOAD REPORT[0m from: facebook/esm1b_t33_650M_UR50S
Key                         | Status     | 
----------------------------+------------+-
lm_head.layer_norm.bias     | UNEXPECTED | 
lm_head.layer_norm.weight   | UNEXPECTED | 
lm_head.dense.bias          | UNEXPECTED | 
lm_head.dense.weight        | UNEXPECTED | 
lm_head.bias                | UNEXPECTED | 
esm.embeddings.position_ids | UNEXPECTED | 
pooler.dense.weight         | MISSING    | 
pooler.dense.bias           | MISSING    | 

[3mNotes:
- UNEXPECTED[3m	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.
- MISSING[3m	:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.[0m
</pre><pre class="output-result">tokenizer_config.json:   0%|          | 0.00/95.0 [00:00&lt;?, ?B/s]</pre><pre class="output-result">vocab.txt:   0%|          | 0.00/93.0 [00:00&lt;?, ?B/s]</pre><pre class="output-result">special_tokens_map.json:   0%|          | 0.00/125 [00:00&lt;?, ?B/s]</pre><pre class="output-stderr">Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
</pre></div>
        </div>
        <p>From the <strong>transformers</strong> library we have imported the <strong>ESM</strong> model and a tokeniser,  <strong>AutoTokenizer</strong>. We will use the tokeniser to encode our text data into a format that the model can understand.</p>
        <div class="info-box tip-box">
            <div class="box-title">
                <span class="box-icon"></span>
                TIP
            </div>
            <div class="box-content">
                <p>Don&#x27;t worry about the warning stating some weights are missing. This is because the EsmModel purposely has some downstream layers untrained for the user to train for their own task. In our case we will just be using the model to generate embeddings and then creating our own prediction neural net.</p>
            </div>
        </div>
        <h4>Checking the contents of a PyTorch model</h4><p>Let&#x27;s check what&#x27;s inside the <strong>ESM1b</strong> model:</p>
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-27">print(model)</code></pre>
            </div>
            <div class="output-container"><pre class="output-stream">EsmModel(
  (embeddings): EsmEmbeddings(
    (word_embeddings): Embedding(33, 1280, padding_idx=1)
    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.0, inplace=False)
    (position_embeddings): Embedding(1026, 1280, padding_idx=1)
  )
  (encoder): EsmEncoder(
    (layer): ModuleList(
      (0-32): 33 x EsmLayer(
        (attention): EsmAttention(
          (self): EsmSelfAttention(
            (query): Linear(in_features=1280, out_features=1280, bias=True)
            (key): Linear(in_features=1280, out_features=1280, bias=True)
            (value): Linear(in_features=1280, out_features=1280, bias=True)
          )
          (output): EsmSelfOutput(
            (dense): Linear(in_features=1280, out_features=1280, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (intermediate): EsmIntermediate(
          (dense): Linear(in_features=1280, out_features=5120, bias=True)
        )
        (output): EsmOutput(
          (dense): Linear(in_features=5120, out_features=1280, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      )
    )
    (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
  )
  (pooler): EsmPooler(
    (dense): Linear(in_features=1280, out_features=1280, bias=True)
    (activation): Tanh()
  )
  (contact_head): EsmContactPredictionHead(
    (regression): Linear(in_features=660, out_features=1, bias=True)
    (activation): Sigmoid()
  )
)
</pre></div>
        </div>
        <p>The model&#x27;s architecture is complex and intricate. However, don&#x27;t worry. You do not need to know the specifics of each layer.<br><br>What&#x27;s crucial to understand is that this model consists of 33 identical <strong>transformer</strong> blocks. The final output layer has a dimension of <strong>1280</strong>, indicating that the model will represent each amino acid as a vector with <strong>1280 scalar values</strong>. This vector representation is commonly referred to as an <em>embedding</em>.</p><h4>Model parameters</h4><p>Having a look at the total model trainig parameters, we can see that this is a fairly large model with just over <strong>650 million parameters</strong> for training. It is this volume of parameters that will make obtain the embeddings so time consuming at the end of this section.</p>
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-28"># The trainable parameters
total_trainable_params = sum(
    p.numel() for p in model.parameters() if p.requires_grad)

print(f&#x27;{total_trainable_params:,} training parameters.&#x27;)</code></pre>
            </div>
            <div class="output-container"><pre class="output-stream">652,356,501 training parameters.
</pre></div>
        </div>
        
                    </div>
                </div>
            </div>
            
            <div class="module-card" id="tokenisation">
                <div class="module-body">
                    <div class="module-section">
                        <h3>Tokenisation</h3>
                        <p>Tokenisation is a crucial step in natural language processing tasks. It involves breaking down text into smaller units, such as words or subwords, to facilitate further processing by machine learning models. In the context of protein sequences, tokenisation is essential to convert the raw amino acid sequences into a format that can be understood and processed by the model. By tokenising protein sequences, we enable the model to learn patterns and relationships within the sequence data, ultimately improving its performance in downstream tasks.</p>
        <div class="info-box note-box">
            <div class="box-title">
                <span class="box-icon"></span>
                NOTE
            </div>
            <div class="box-content">
                <p>Tokenisation is different to embedding. The tokens are the <strong>keys</strong> (numerical) that the model knows to be associated with its pre-trained embeddings.</p>
            </div>
        </div>
        
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-29"># Tokenizer can convert protein sequences into a list of index tokens
seq = &#x27;ACFGPLOIE&#x27;
print(seq)
print(f&quot;Sequence of length: {len(seq)}&quot;, &quot;\n&quot;)

tokens = tokenizer(seq, return_tensors=&quot;pt&quot;)
print(tokens[&#x27;input_ids&#x27;])
print(f&quot;Tokens of length: {len(tokens[&#x27;input_ids&#x27;][0])}&quot;)</code></pre>
            </div>
            <div class="output-container"><pre class="output-stream">ACFGPLOIE
Sequence of length: 9 

tensor([[ 0,  5, 23, 18,  6, 14,  4, 28, 12,  9,  2]])
Tokens of length: 11
</pre></div>
        </div>
        <p>The tokeniser converts a protein sequence into index tokens according to a vocabulary dictionary (see below).<br><br>However, you will notice that the token tensor is 2 items longer than the input sequence.<br>This is because the tokeniser adds a special token <code>[cls]</code> at the beginning of the sequence and a <code>[eos]</code> (indicates &quot;end of sequence&quot;) at the end of the sequence.<br>You can either keep or ignore the these special tokens. But you need to be aware of them.</p><p>To have a better understanding about the index showing above in the &#x27;input_ids&#x27;, you can view the token dictionary by using .get_vocab() function</p>
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-30">token_dict = tokenizer.get_vocab()

for c, (k, v) in enumerate(token_dict.items()):
    print(f&quot;{k}: {v}&quot;)

    if c == 8:
        break</code></pre>
            </div>
            <div class="output-container"><pre class="output-stream">&lt;cls&gt;: 0
&lt;pad&gt;: 1
&lt;eos&gt;: 2
&lt;unk&gt;: 3
L: 4
A: 5
G: 6
V: 7
S: 8
</pre></div>
        </div>
        
                    </div>
                </div>
            </div>
            
            <div class="module-card" id="tokenisation">
                <div class="module-body">
                    <div class="module-section">
                        
        <div class="info-box practice-exercise-box">
            <div class="box-title">
                <span class="box-icon"></span>
                PRACTICE EXERCISE
            </div>
            <div class="box-content">
                <p><strong>1.</strong></p>
                <p>Convert the sequence <code>AOPIEYTLKQGFMCV</code> into tokens.</p>
            </div>
        </div>
        
                    </div>
                </div>
            </div>
            
            <div class="module-card" id="fetch-an-embedding">
                <div class="module-body">
                    <div class="module-section">
                        <h3>Fetch an embedding</h3>
                        <p>After converting the sequence into tokens, we can use the model to get the <strong>embeddings</strong> of the tokenised sequence.</p>
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-31">seq = &#x27;AOPIEYTLKQGFMCV&#x27;
new_seq_token = tokenizer(seq,return_tensors=&quot;pt&quot;)
new_seq_token.to(device)

with torch.no_grad():
    outputs = model(**new_seq_token) # generate the embeddings

outputs.keys()</code></pre>
            </div>
            <div class="output-container"><pre class="output-result">odict_keys([&#x27;last_hidden_state&#x27;, &#x27;pooler_output&#x27;])</pre></div>
        </div>
        <p>The <code>outputs</code> contains two keys: <code>last_hidden_state</code> and <code>pooler_output</code>. <code>last_hidden_state</code> is the sequence embedding from the last layer of the model. Usually, we take <code>last_hidden_state</code> as the representation of the input protein sequence.</p>
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-32">outputs[&#x27;last_hidden_state&#x27;].shape</code></pre>
            </div>
            <div class="output-container"><pre class="output-result">torch.Size([1, 17, 1280])</pre></div>
        </div>
        <h4>Breaking down the tensor `[1, 17, 1280]`</h4><p><ul class="nested-list"><li>The first dimension indicates there is only <code>one</code> sequence. If we feed two sequences into the model, the first dimension will be two.</li><br><li>The second dimension refers to the length of the protein sequence. Note, as mentioned above, the input_token includes two special tokens <code>[cls]</code> and <code>[eos]</code>. Thus, though the length of the original sequence is 15, the length of the final input fed into the model is 17</li><br><li>The third dimension here is the <code>fixed dimension</code> of representation. Here, the dimension is 1280, which indicates that each amino acid is represented by 1280 scalars.</li></ul></p><h4>Embeddings are context dependent:</h4><p>Ass disussed in the prior sub--section the <strong>embedding vector</strong> for each amino acid will change dependent on where it is in a sequence and what sequence it is in due to the <strong>attention mechanism</strong>, in other words it is <strong>context independent</strong>.<br><br>This can be seen by comparing the amino acid <code>&#x27;A&#x27;</code> (Alanine) when on its own or part of <code>&#x27;AO&#x27;</code> (Alanine-Pyrrolysine):</p>
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-33"># Define our sequences and tokenise
seqA = &#x27;A&#x27;
seqA_token = tokenizer(seqA,return_tensors=&quot;pt&quot;)
seqA_token.to(device)

seqAO = &#x27;AO&#x27;
seqAO_token = tokenizer(seqAO,return_tensors=&quot;pt&quot;)
seqAO_token.to(device)

# Get embeddings
with torch.no_grad():
    seqA_output = model(**seqA_token)
    seqAO_output = model(**seqAO_token)

# Extract the embedding of only Alanine
a_embedding_own = seqA_output[&#x27;last_hidden_state&#x27;][0][1] 
a_embedding_withO = seqAO_output[&#x27;last_hidden_state&#x27;][0][1]

print(f&quot;Embedding of A (on its own): {a_embedding_own}&quot;)
print(f&quot;Embedding of A (on its own): {a_embedding_withO}&quot;)
print(&quot; &quot;)
print(f&quot;Are they equivalent: {all(a_embedding_own == a_embedding_withO)}&quot;)</code></pre>
            </div>
            <div class="output-container"><pre class="output-stream">Embedding of A (on its own): tensor([ 0.1134, -0.0101,  0.2522,  ..., -0.1973, -0.0275, -0.1833])
Embedding of A (on its own): tensor([ 0.0448, -0.1421,  0.1985,  ..., -0.2687, -0.0183, -0.2628])
 
Are they equivalent: False
</pre></div>
        </div>
        <h4>Multiple sequences:</h4><p>To fetch embeddings for multiple sequences, you can simply put the sequences as individual items in a list:</p>
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-34">seq = [&#x27;AOPIEYTLKQGFMCV&#x27;,&#x27;MOPDEYTWK&#x27;]
new_seq_token = tokenizer(seq, return_tensors=&quot;pt&quot;)</code></pre>
            </div>
            <div class="output-container"><pre class="output-error">ValueError on line 4: Unable to create tensor, you should probably activate truncation and/or padding with &#x27;padding=True&#x27; &#x27;truncation=True&#x27; to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).</pre></div>
        </div>
        <p>However, in most cases, the sequences in the input list have different lengths, thus we will get embeddings of different sizes. As a tensor needs to be a matrix, our embeddings need to be the same length.<br><br>To achieve this we use padding. Padding is a process where we add a special token to the end of the sequence to make it the same length as the longest sequence in the list.<br><br>In this case we add the argument <code>True</code> to the <code>padding</code> parameter. Here, the <code>[pad]</code> token (which is 1 in this case) to the end of the shorter sequences. Additionally, it will use &quot;0&quot; in the attention_mask to indicate which tokens are <code>[pad]</code> tokens. This ensures that all sequences are padded to the same length, enabling the model to process them in batches effectively.</p>
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-35">seq = [&#x27;AOPIEYTLKQGFMCV&#x27;,&#x27;MOPDEYTWK&#x27;]
new_seq_tokens = tokenizer(seq, return_tensors=&quot;pt&quot;, padding=True)
# To move all the token sequences to device in one go, use dictionary comprehension
new_seq_tokens = {k: v.to(device) for k, v in new_seq_tokens.items()}
with torch.no_grad():
    outputs = model(**new_seq_tokens) # generate the embeddings

outputs[&#x27;last_hidden_state&#x27;].shape</code></pre>
            </div>
            <div class="output-container"><pre class="output-result">torch.Size([2, 17, 1280])</pre></div>
        </div>
        <p>When we give a list of <strong>two</strong> sequences and pad them, the value in the first dimension increases by <strong>one</strong> to <strong>two</strong>.</p>
                    </div>
                </div>
            </div>
            
            <div class="module-card" id="embedding-extraction">
                <div class="module-body">
                    <div class="module-section">
                        <h3>Embedding Extraction</h3>
                        <p>We will generate embeddings using <strong>ESM-1b</strong> for both the wildtype sequence and the mutated sequence.<br><br>However, ESM-1b can only accept protein sequence with the maximum length of <strong>1022</strong>, some of our seqeunces are longer than this.</p>
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-36">import pandas as pd

# Load in our processed data
train = pd.read_csv(&quot;./data/processed_train.csv&quot;)
test = pd.read_csv(&quot;./data/processed_test.csv&quot;)

print(f&quot;Number of sequences &gt; 1022; Train: {len(train[train[&#x27;Length&#x27;] &gt; 1022])}, Test: {len(test[test[&#x27;Length&#x27;] &gt; 1022])}&quot;)</code></pre>
            </div>
            <div class="output-container"><pre class="output-stream">Number of sequences &gt; 1022; Train: 50602, Test: 10483
</pre></div>
        </div>
        <p>There are multiple ways to process the protein sequences, to ensure they fit our <em>model</em>. The <a href="https://github.com/wlin16/VariPred"><strong>VariPred</strong></a> package applies a <strong>truncation</strong> stratergy around the mutation point. Here, for the sake of demonstration purposes we will remove the sequences that are too long.</p>
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-37">train = train[train[&#x27;Length&#x27;] &lt;= 1022].copy()
test = test[test[&#x27;Length&#x27;] &lt;= 1022].copy()</code></pre>
            </div>
            
        </div>
        
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-38">import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize = (8, 4))

ax.hist(train[&quot;wt_seq&quot;].str.len(), alpha = 0.5, density=True, label = &quot;Train&quot;)
ax.hist(test[&quot;wt_seq&quot;].str.len(), alpha = 0.5, density=True, label = &quot;Test&quot;)
ax.set_title(&quot;Distribution of Sequence Lengths (density)&quot;)
ax.legend()

plt.show()</code></pre>
            </div>
            <div class="output-container"><img src="data:image/png;base64,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" class="output-image" width="698" height="374" /></div>
        </div>
        <p>Now, finally, our dataset is ready to be used by the model.</p><h4>Generate embeddings from the model</h4><p>There are two ways to deal with the feature extraction during the classification model training:<br><ol class="nested-list"><li>Generate the embeddings for the given dataset repeatly during the training.</li><br><li>Generate the embeddings from the dataset once, save it as a binary file into your disk. Read such embedding file into the RAM (memory) when we need to train the model.</li></ol></p><p>The first method saves disk storage space, however, it usually takes a much longer time because the embeddings of each sequence have to be generated again and again during the training.<br><br>The second method needs to occupy a bit more storage space as it stores the generated embeddings to the disk. However, since we can directly feed the embedding into the model for training, the entire training process can speed up dramatically.<br><br>In this case, we will apply the second method.</p>
                    </div>
                </div>
            </div>
            
            <div class="module-card" id="embeddings-to-disk">
                <div class="module-body">
                    <div class="module-section">
                        <h3>Embeddings to disk</h3>
                        <p>The previous histograms show that the sequence lengths varies a lot even after we trunctated the sequences. Embeddings can be generated for these sequences at the same time by calling the model on the list of sequences (as we demonstrated above). However for the amound of sequences we would like to produce, this will consume a lot of memory dur to parallel computing and padding.</p><h4>Why?</h4><p>Let&#x27;s image we need apply the tokeniser for mixed sequences with the shortest length (54) and the longest length (1022). The input tokens fed into the model will always be padded into the length of the longest sequence (1022). Generating the embedding for a sequence with only 54 amino acid will only take: $$54 * 1280 * 4 / 1024 /1024 = 0.27GB$$, but this number will increase to about 5GB if we are going to generate the embedding for a sequence with 1022 amino acids.<br><br>So when encountering amino acid sequences with different length it can be more efficient to implement your own tokeniser/embedding workflow with a <code>for-loop</code>.</p>
        <div class="info-box warning-box">
            <div class="box-title">
                <span class="box-icon"></span>
                WARNING
            </div>
            <div class="box-content">
                <p>Typically trying to run the original workflow will crash the workspace environment due to using up all avaiable RAM. Try it for yourself and see:<br><br><pre class="markdown-code-block"><code>seq_test = test[&quot;wt_seq&quot;].tolist()

seq_tokens = tokenizer(seq_test, return_tensors=&quot;pt&quot;, padding=True)
seq_tokens = {k: v.to(device) for k, v in seq_tokens.items()} # Move tokeniser output to device 

with torch.no_grad():
    outputs = model(**seq_tokens) # generate the embeddings</code></pre><br><br>This will cause the kernel to crash.<br></p>
            </div>
        </div>
        <h4>Implementation</h4><p>For the next workflow we will generate the <strong>embeddings</strong> for the amino acids occuring at the mutation poistion, for both the <em>wildtype</em> and <em>mutated</em> sequences. Together, they will be a representation for the <strong>wt-mt</strong> sequence pair.<br><br>To obtain this we will need to generate the whole embedding for each sequence, to ensure its <em>context dependent</em>, and then select just the embeddings at our known mutational point. These two embedding can then be <em>concatenated</em> together to provide a vector with information from both.</p>
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-39">from tqdm import tqdm

def get_embeddings(dataset):
    
    # Initialise an empty dictionary to store the data
    data_dict = {&quot;target_id&quot;: [], &quot;embeddings&quot;: [], &quot;labels&quot;: []}
    
    # Iterate over the rows in the test dataset
    with torch.no_grad():

        for index, row in tqdm(dataset.iterrows()):  # Use index along with row

            # Tokenise the wildtype and mutated sequences
            wt_token = tokenizer(row[&#x27;wt_seq&#x27;], return_tensors=&quot;pt&quot;)
            wt_token = {k: v.to(device) for k, v in wt_token.items()} # Move tokeniser output to device 
            
            mt_token = tokenizer(row[&#x27;mt_seq&#x27;], return_tensors=&quot;pt&quot;)
            mt_token = {k: v.to(device) for k, v in mt_token.items()} # Move tokeniser output to device 

            # Get the index of the amino acid
            aa_index = row[&#x27;aa_index&#x27;]

            # Generate embeddings for wildtype and mutated sequences
            wt_emb = model(**wt_token)
            mt_emb = model(**mt_token)
            
            # Extract the last_hidden_state (the actual embeddings) from the model output
            wt_hidden = wt_emb[&#x27;last_hidden_state&#x27;] 
            mt_hidden = mt_emb[&#x27;last_hidden_state&#x27;] 
            
            # Extract the embeddings at the specified amino acid index
            wt_out = wt_hidden[:, aa_index, :].cpu().detach()
            mt_out = mt_hidden[:, aa_index, :].cpu().detach()
            
            # Concatenate the wildtype and mutated amino acids&#x27; embeddings
            concat = torch.cat([wt_out, mt_out], dim=-1).squeeze(0)  # Concatenate along feature dimension
            
            # Store the id, concatenated embeddings and label in the dictionary
            data_dict[&#x27;target_id&#x27;].append(row[&#x27;target_id&#x27;])
            data_dict[&#x27;embeddings&#x27;].append(concat)
            data_dict[&#x27;labels&#x27;].append(row[&#x27;label&#x27;])
    
    return data_dict
</code></pre>
            </div>
            
        </div>
        <p>To save the data for the next section we can store the resultant data dictionary as a pickle file.<br><br>The <a href="https://docs.python.org/3/library/pickle.html">pickle module</a> converts any Python object into a <em>byte stream</em> than can be later decoded back into the same object when loaded. It is one of the go to methods for saving in Python and is one of the <em>built-in</em> modules that doesn&#x27;t require installing.</p>
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-40">import pickle</code></pre>
            </div>
            
        </div>
        <p>Running the above function for both the training and test dataset would take a prohibitively long time on just a <strong>CPU</strong>. Running it on a local computer was calculated to take roughly <strong>25 hours</strong> for the <em>train</em> dataset (80 000 samples).<br><br>Even when running it with a <strong>GPU</strong> the process still took approximately <strong>5 hours</strong> for the <em>train</em> dataset. Given this we have stored the embeddings in the <code>./data</code> folder in your repository.<br><br>The code below would be what you would need to run.</p>
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-41">train_data_dict = get_embeddings(train)

with open(&#x27;./data/embs_for_train.pkl&#x27;, &#x27;wb&#x27;) as file:
    pickle.dump(train_data_dict, file)
    print(&#x27;Data saved successfully&#x27;)</code></pre>
            </div>
            
        </div>
        
        <div class="code-area">
            <div class="code-container code-fixed">
                <pre><code class="language-python" id="code-42">test_data_dict = get_embeddings(test)

with open(&#x27;./data/embs_for_test.pkl&#x27;, &#x27;wb&#x27;) as file:
    pickle.dump(test_data_dict, file)
    print(&#x27;Data saved successfully&#x27;)</code></pre>
            </div>
            
        </div>
        
                    </div>
                </div>
            </div>
            
            <div class="module-card" id="summary">
                <div class="module-body">
                    <div class="module-section">
                        <h3>Summary</h3>
                        <p>In this section we have progressed from mutational sequences to a <strong>scaler vector</strong> that is encoded with historical, contextual information about both the <em>wildtype</em> and <em>mutated</em> amino acid.<br><br>In the next section, we are going to train a classifier on the representations that have been generated</p>
                    </div>
                </div>
            </div>
            
        
        <div class="page-navigation">
            <a href="./data-processing.html" class="nav-button prev">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                    <path d="M15.41 7.41L14 6l-6 6 6 6 1.41-1.41L10.83 12z"/>
                </svg>
                Previous
            </a>
            <a href="./classifying-embeddings.html" class="nav-button next">
                Next
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                    <path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"/>
                </svg>
            </a></div>
        
        <!-- Footer -->
        <div class="footer">
            <div>¬© All materials are copyright scryptIQ 2025</div>
            <div>Static Notebook - Pre-executed Content</div>
        </div>
    </div>

    <!-- JavaScript -->
    <script src="../assets/main.js"></script>
    
    <!-- Initialize syntax highlighting -->
    <script>
        // Set page ready flag immediately for PDF generation
        window.pageReady = true;
        
        document.addEventListener('DOMContentLoaded', function() {
            document.querySelectorAll('pre code').forEach((block) => {
                hljs.highlightElement(block);
            });
        });
    </script>
</body>
</html>
    